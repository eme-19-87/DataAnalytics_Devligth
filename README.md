# ğŸ“¦ Proyecto Final -- Data Warehouse para E-Commerce Brazil (Olist)

Este repositorio contiene el desarrollo completo de un **Data Warehouse** construido a partir del conjunto de datos pÃºblico de comercio electrÃ³nico de Brasil publicado por **Olist Store** en Kaggle.
El proyecto adopta la **arquitectura MedallÃ³n (Bronce â†’ Plata â†’ Oro)** e implementa procesos ETL para limpieza, normalizaciÃ³n, modelado dimensional y anÃ¡lisis final.

## ğŸ§­ Tabla de Contenidos

1.  ğŸ¯ Objetivo del Proyecto
2.  ğŸ› ï¸ Herramientas Utilizadas
3.  ğŸ—ï¸ Arquitectura
4.  ğŸ“‚ Sistema Fuente (Datasets)
5.  ğŸ¥‰ Capa Bronce
6.  ğŸ¥ˆ Capa Plata -- Limpieza y EstandarizaciÃ³n
7.  ğŸ¥‡ Capa Oro -- Modelo Dimensional
8.  ğŸ“Š Dashboards en Reflex
9.  ğŸ“ Estructura del Repositorio
10. ğŸ› ï¸ EjecuciÃ³n Del Proyecto
11. ğŸ“š Referencias

<hr style="border: solid black 0.5em">

## ğŸ¯ Objetivo del Proyecto

El objetivo es construir un **Data Warehouse robusto y confiable** que: 
- Integre datos provenientes de archivos CSV crudos. 
- Aplique procesos de limpieza, estandarizaciÃ³n y control de calidad. 
- Modele un esquema dimensional eficiente para anÃ¡lisis. 
- Permita generar dashboards y reportes de valor. 
- Mejore la toma de decisiones para un entorno de comercio electrÃ³nico.

<hr style="border: solid black 0.5em">

## ğŸ› ï¸ Herramientas Utilizadas

Herramienta Uso

---

PostgreSQL Motor del Data Warehouse.
Reflex VisualizaciÃ³n de dashboards.
GitHub Control de versiones.
Draw.io Diagramas de arquitectura.
Python Como lenguaje para crear los dashboards con ayuda de Reflex.
Trello Registro de actividades para el desarrollo del proyecto.

<hr style="border: solid black 0.5em">

## ğŸ—ï¸ Arquitectura

La arquitectura sigue el modelo **MedallÃ³n**:
### ğŸ¥‰ Bronce
Datos en bruto, sin transformaciÃ³n.
### ğŸ¥ˆ Plata
Limpieza, estandarizaciÃ³n e imputaciÃ³n.
### ğŸ¥‡ Oro
Modelo dimensional orientado a anÃ¡lisis.

<img src="Documentacion/imagenes/Arquitectura.png">

## ğŸ“‚ Sistema Fuente (Datasets)

- olist_customers_dataset.csv
- olist_geolocation_dataset.csv
- olist_orders_dataset.csv
- olist_order_items_dataset.csv
- olist_order_payments_dataset.csv
- olist_order_reviews_dataset.csv
- olist_products_dataset.csv
- olist_sellers_dataset.csv
- product_category_name_translation.csv

---

ğŸ“˜ olist_customers_dataset.csv

Este conjunto de datos contiene informaciÃ³n sobre los clientes y sus localizaciones.
Permite identificar clientes Ãºnicos a partir del campo customer_unique_id, ya que el mismo cliente puede tener diferentes customer_id en distintas Ã³rdenes.
Se usa para unir informaciÃ³n de geolocalizaciÃ³n con las Ã³rdenes del dataset principal.

<table> <tr><th style="border:2px solid black;">Campos</th><th style="border:2px solid black;">ExplicaciÃ³n</th></tr> <tr><td style="border:2px solid black;">customer_id</td><td style="border:2px solid black;">Clave en olist_orders_dataset. Cada orden tiene un customer_id Ãºnico.</td></tr> <tr><td style="border:2px solid black;">customer_unique_id</td><td style="border:2px solid black;">Identificador Ãºnico del cliente para detectar recompras.</td></tr> <tr><td style="border:2px solid black;">customer_zip_code_prefix</td><td style="border:2px solid black;">Primeros cinco dÃ­gitos del cÃ³digo ZIP del cliente.</td></tr> <tr><td style="border:2px solid black;">customer_city</td><td style="border:2px solid black;">Ciudad del cliente.</td></tr> <tr><td style="border:2px solid black;">customer_state</td><td style="border:2px solid black;">Estado del cliente.</td></tr> </table>

---

ğŸ“˜ olist_geolocation_dataset.csv

Este dataset contiene los cÃ³digos ZIP de Brasil junto con sus coordenadas geogrÃ¡ficas.
Se utiliza para calcular distancias, construir mapas y validar ciudades o estados provenientes de otros datasets (clientes o vendedores).

<table> <tr><th style="border:2px solid black;">Campos</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">geolocation_zip_code_prefix</td><td style="border:2px solid black;">Primeros cinco dÃ­gitos del cÃ³digo ZIP.</td></tr> <tr><td style="border:2px solid black;">geolocation_lat</td><td style="border:2px solid black;">Latitud.</td></tr> <tr><td style="border:2px solid black;">geolocation_lng</td><td style="border:2px solid black;">Longitud.</td></tr> <tr><td style="border:2px solid black;">geolocation_city</td><td style="border:2px solid black;">Ciudad registrada.</td></tr> <tr><td style="border:2px solid black;">geolocation_state</td><td style="border:2px solid black;">Estado registrado.</td></tr> </table>

---

ğŸ“˜ olist_order_items_dataset.csv

Contiene los Ã­tems incluidos dentro de cada orden.
Cada producto dentro de una orden se identifica con order_item_id, y el flete se distribuye proporcionalmente entre los Ã­tems.

<table> <tr><th style="border:2px solid black;">Campo</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">order_id</td><td style="border:2px solid black;">Identificador Ãºnico de la orden.</td></tr> <tr><td style="border:2px solid black;">order_item_id</td><td style="border:2px solid black;">Secuencia del Ã­tem dentro de la orden.</td></tr> <tr><td style="border:2px solid black;">product_id</td><td style="border:2px solid black;">Identificador del producto.</td></tr> <tr><td style="border:2px solid black;">seller_id</td><td style="border:2px solid black;">Identificador del vendedor.</td></tr> <tr><td style="border:2px solid black;">shipping_limit_date</td><td style="border:2px solid black;">Fecha lÃ­mite de despacho.</td></tr> <tr><td style="border:2px solid black;">price</td><td style="border:2px solid black;">Precio del Ã­tem.</td></tr> <tr><td style="border:2px solid black;">freight_value</td><td style="border:2px solid black;">Costo del flete correspondiente a este Ã­tem.</td></tr> </table>

---

ğŸ“˜ olist_order_payments_dataset.csv

Incluye los datos del mÃ©todo y detalle del pago de cada orden.
Una orden puede tener mÃºltiples mÃ©todos de pago.

<table> <tr><th style="border:2px solid black;">Campos</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">order_id</td><td style="border:2px solid black;">Identificador de la orden.</td></tr> <tr><td style="border:2px solid black;">payment_sequential</td><td style="border:2px solid black;">NÃºmero de secuencia del pago.</td></tr> <tr><td style="border:2px solid black;">payment_type</td><td style="border:2px solid black;">MÃ©todo de pago utilizado.</td></tr> <tr><td style="border:2px solid black;">payment_installments</td><td style="border:2px solid black;">Cantidad de cuotas del pago.</td></tr> <tr><td style="border:2px solid black;">payment_value</td><td style="border:2px solid black;">Monto total pagado.</td></tr> </table>

---

ğŸ“˜ olist_order_reviews_dataset.csv

Contiene las reseÃ±as escritas por los clientes, junto con la puntuaciÃ³n y tiempos de respuesta.

<table> <tr><th style="border:2px solid black;">Campos</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">review_id</td><td style="border:2px solid black;">Identificador Ãºnico de la reseÃ±a.</td></tr> <tr><td style="border:2px solid black;">order_id</td><td style="border:2px solid black;">Orden asociada.</td></tr> <tr><td style="border:2px solid black;">review_score</td><td style="border:2px solid black;">PuntuaciÃ³n (1 a 5).</td></tr> <tr><td style="border:2px solid black;">review_comment_title</td><td style="border:2px solid black;">TÃ­tulo de la reseÃ±a.</td></tr> <tr><td style="border:2px solid black;">review_comment_message</td><td style="border:2px solid black;">Contenido del comentario.</td></tr> <tr><td style="border:2px solid black;">review_creation_date</td><td style="border:2px solid black;">Fecha en que el cliente enviÃ³ la reseÃ±a.</td></tr> <tr><td style="border:2px solid black;">review_answer_timestamp</td><td style="border:2px solid black;">Fecha en que la tienda respondiÃ³ la reseÃ±a.</td></tr> </table>

---

ğŸ“˜ olist_orders_dataset.csv

Este es el dataset central del proyecto.
Cada orden estÃ¡ conectada con clientes, Ã­tems, pagos, reseÃ±as y fechas logÃ­sticas.

<table> <tr><th style="border:2px solid black;">Campo</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">order_id</td><td style="border:2px solid black;">Identificador Ãºnico de la orden.</td></tr> <tr><td style="border:2px solid black;">customer_id</td><td style="border:2px solid black;">Clave al dataset de clientes.</td></tr> <tr><td style="border:2px solid black;">order_status</td><td style="border:2px solid black;">Estado de la orden (delivered, shipped, etc.).</td></tr> <tr><td style="border:2px solid black;">order_purchase_timestamp</td><td style="border:2px solid black;">Fecha de compra.</td></tr> <tr><td style="border:2px solid black;">order_approved_at</td><td style="border:2px solid black;">Fecha de aprobaciÃ³n.</td></tr> <tr><td style="border:2px solid black;">order_delivered_carrier_date</td><td style="border:2px solid black;">Fecha en que el delivery recibiÃ³ el paquete.</td></tr> <tr><td style="border:2px solid black;">order_delivered_customer_date</td><td style="border:2px solid black;">Fecha de entrega al cliente.</td></tr> <tr><td style="border:2px solid black;">order_estimated_delivery_date</td><td style="border:2px solid black;">Fecha estimada de entrega.</td></tr> </table>

---

ğŸ“˜ olist_products_dataset.csv

Dataset que contiene informaciÃ³n estructural sobre los productos vendidos.

<table> <tr><th style="border:2px solid black;">Campos</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">product_id</td><td style="border:2px solid black;">Identificador del producto.</td></tr> <tr><td style="border:2px solid black;">product_category</td><td style="border:2px solid black;">CategorÃ­a raÃ­z (en portuguÃ©s).</td></tr> <tr><td style="border:2px solid black;">product_name_length</td><td style="border:2px solid black;">Longitud del nombre del producto.</td></tr> <tr><td style="border:2px solid black;">product_description_length</td><td style="border:2px solid black;">Longitud de la descripciÃ³n.</td></tr> <tr><td style="border:2px solid black;">product_photo_qty</td><td style="border:2px solid black;">Cantidad de fotos del producto.</td></tr> <tr><td style="border:2px solid black;">product_weight_g</td><td style="border:2px solid black;">Peso en gramos.</td></tr> <tr><td style="border:2px solid black;">product_length_cm</td><td style="border:2px solid black;">Longitud en cm.</td></tr> <tr><td style="border:2px solid black;">product_height_cm</td><td style="border:2px solid black;">Altura en cm.</td></tr> <tr><td style="border:2px solid black;">product_width_cm</td><td style="border:2px solid black;">Ancho en cm.</td></tr> </table>

---

ğŸ“˜ olist_sellers_dataset.csv

Contiene informaciÃ³n de los vendedores que procesan pedidos para Olist.

<table>
<tr style="border:2px solid black;">
<th style="border:2px solid black;">Campo</th><th >Significado</th>
</tr> 
<tr style="border:2px solid black;"><td style="border:2px solid black;">seller_id</td><td >Identificador Ãºnico del vendedor.</td>
</tr> <tr style="border:2px solid black;"><td style="border:2px solid black;">seller_zip_code_prefix</td><td>Primeros cinco dÃ­gitos del ZIP.</td></tr> <tr style="border:2px solid black;"><td>seller_city</td><td style="border:2px solid black;">Ciudad del vendedor.</td></tr> <tr style="border:2px solid black;"><td style="border:2px solid black;">seller_state</td><td>Estado del vendedor.</td></tr> </table>


---

ğŸ“˜ product_category_name_translation.csv

Dataset de apoyo para traducir categorÃ­as del portuguÃ©s al inglÃ©s.

<table> <tr><th style="border:2px solid black;">Campo</th><th style="border:2px solid black;">Significado</th></tr> <tr><td style="border:2px solid black;">product_category_name</td><td style="border:2px solid black;">Nombre de la categorÃ­a en portuguÃ©s.</td></tr> <tr><td style="border:2px solid black;">product_category_name_english</td><td style="border:2px solid black;">Nombre traducido al inglÃ©s.</td></tr> </table>

## ğŸ¥‰ Capa Bronce

Carga cruda mediante tablas espejo y procesos Truncate + Insert.

<img src="Documentacion/imagenes/Flujo De Datos.png">

## ğŸ¥ˆ Capa Plata -- Limpieza y EstandarizaciÃ³n

Incluye limpieza de productos, geolocalizaciÃ³n, clientes, vendedores, Ã³rdenes, Ã­tems de Ã³rdenes, pagos y reseÃ±as. Algunos de los controles realizados en las entidades se muestran a continuaciÃ³n:

---

ğŸ“¦ Productos

ImputaciÃ³n de nulos usando la mediana por categorÃ­a.

CÃ¡lculo de peso faltante: peso = alto Ã— ancho Ã— largo Ã— factor.

NormalizaciÃ³n de texto y eliminaciÃ³n de espacios.

CorrecciÃ³n de valores â‰¤ 0 en dimensiones.

AsignaciÃ³n de 0 cuando faltan longitudes o fotos.

---

ğŸ—ºï¸ GeolocalizaciÃ³n

Promedio de latitud y longitud por cÃ³digo ZIP.

EliminaciÃ³n de duplicados derivados de mÃºltiples lecturas GPS.

ValidaciÃ³n cruzada con clientes y vendedores.

IdentificaciÃ³n de ciudades no presentes en este dataset mediante Python y PostgreSQL.

---

ğŸ‘¤ Clientes

ValidaciÃ³n de unicidad de customer_id.

customer_unique_id repetido aceptado (recompras).

CorrecciÃ³n de errores de tipeo en ciudades mediante:

Coincidencia parcial.

ComparaciÃ³n con ZIP.

Fuentes externas cuando es posible.

Registros sin fuente confiable se mantienen.

---

ğŸ›’ Vendedores

Proceso igual al de clientes:

ValidaciÃ³n de ZIP.

Control de nulos.

CorrecciÃ³n de ciudades cuando aplica.

---

ğŸ“¦ Ã“rdenes

Controles aplicados:

No nulos en order_id y customer_id.

No duplicados en order_id.

ValidaciÃ³n secuencial de fechas:

purchase

approved

delivered_carrier

delivered_customer

CorrecciÃ³n automÃ¡tica:

Si una fecha es incoherente â†’ se ajusta para que sea un dÃ­a mayor.

Se aplica solo a Ã³rdenes delivered.

---

ğŸ›ï¸ Ãtems de Orden

price > 0

freight_value â‰¥ 0

---

ğŸ’³ Pagos

payment_value > 0 excepto para voucher y not_defined.

payment_sequential > 0

payment_installments > 0

CorrecciÃ³n para casos donde figura 0 cuotas.

ComparaciÃ³n del monto total pagado vs. costo total de la orden.

---

â­ ReseÃ±as

review_creation_date <= review_answer_timestamp

review_score > 0, caso contrario â†’ imputaciÃ³n con mediana.



<div style="margin-top:1em">
  <img src="Documentacion/imagenes/Flujo De Datos_CapaPlata.png">
</div>

## ğŸ¥‡ Capa Oro -- Modelo Dimensional

### Dimensiones

- dim_customers
- dim_sellers
- dim_products
- dim_calendar
- dim_status

### Hechos

- fact_sales

### Granularidad

- Un registro en la tabla de hechos representa un item de compra.

<div style="margin-top:1em">
  <img src="Documentacion/imagenes/Diagrama Estrella.png">
  <p style="text-align: center; margin-top:20px">Diagrama Del Modelo Estrella</p>
</div>

<div style="margin:15px auto;">
  <img src="Documentacion/imagenes/Flujo De Datos_CapaOro.drawio.png">
  <p style="text-align: center; margin-top:20px">Diagrama Del Flujo De Datos</p>
</div>
<hr style="border: solid black 0.5em">

## ğŸ“Š Dashboards en Reflex

Incluyen anÃ¡lisis de ventas como principal tabla de hechos. PermitirÃ¡ mostrar de manera dinÃ¡mica las ventas
por cliente, vendedor, ciudades, estados, estados de las ordenes, y diferentes Ã¡mbitos de fecha como ser:
por mes, por dÃ­a, por cuatrimestre, etc.

<hr style="border: solid black 0.5em">

## ğŸ“ Estructura del Repositorio

<p>ğŸ“¦ Repo-ProyectoFinal-Devlight</p>
<p>â”œâ”€â”€ Documentacion</p>
<p>â”‚       â”œâ”€â”€ drawio<p>
<p>â”‚       â”œâ”€â”€ imagenes<p>
<p>â”œâ”€â”€ Scripts<p>
<p>â”‚       â”œâ”€â”€ Bronze<p>
<p>â”‚       â”œâ”€â”€ Silver<p>
<p>â”‚       â”œâ”€â”€ Gold<p>
<p>â””â”€â”€ README.md<p>



<ul>
<li>Documentacion: Los diferentes artefactos para explicar las partes del proyecto.
  <ul>
    <li>drawio: Los archivos drawio empleados</li>
    <li>imagenes: Los imagenes del flujo de datos, arquitectura, relaciones entre entidades,etc.</li>
  </ul>
</li>
<li>Scripts: Los scripts para la creaciÃ³n de las capas, creaciÃ³n de las tablas, limpieza, imputaciÃ³n, estandarizaciÃ³n y control en cada una de ellas.
  <ul>
    <li>Bronze: Scripts para la creaciÃ³n de la capa bronce y la carga de los datos crudos</li>
    <li>Silver: Scripts para la creaciÃ³n de la capa plata, limpieza, imputaciÃ³n, estandarizaciÃ³n y carga de las tablas.</li>
     <li>Oro: Scripts para la creaciÃ³n de la capa oro. CreaciÃ³n del modelo estrella con las tablas de hechos y dimensiones.</li>
  </ul>
</li>
</ul>
    


<hr style="border: solid black 0.5em">

## ğŸ“š EjecuciÃ³n Del Proyecto

### Haciendo Funcionar A Docker

El proyecto fue ejecutado en Docker. Ã‰ste puede ser instalado siguiendo las instrucciones indicadas en el enlace: <a href="https://www.docker.com/get-started/">Iniciar Con Docker</a>.
Una vez instalado Docker, empleamos el siguiente archivo para  docker-compose:
<code>
version: "3.9"

services:
  postgres:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: postgres_bootcamp
    restart: unless-stopped
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: bootcamp_db
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      - ./import_data:/import_data
    networks:
      - postgres_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U myuser -d bootcamp_db"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin_bootcamp
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin123
    ports:
      - "8080:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
      - ./import_data:/import_data
    networks:
      - postgres_network
    depends_on:
      postgres:
        condition: service_healthy

  metabase:
    image: metabase/metabase:latest
    container_name: metabase_bootcamp
    restart: unless-stopped
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: bootcamp_db
      MB_DB_PORT: 5432
      MB_DB_USER: myuser
      MB_DB_PASS: mypassword
      MB_DB_HOST: postgres
    ports:
      - "3000:3000"
    volumes:
      - metabase_data:/metabase-data
    networks:
      - postgres_network
    depends_on:
      - postgres
    healthcheck:
      test: curl --fail -s http://localhost:3000/api/health || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  
networks:
  postgres_network:
    driver: bridge

volumes:
  pgadmin_data:
  metabase_data:
</code>

Y el siguiente archivo para Dockerfile

<code>
  FROM postgres:16
  EXPOSE 5432

  VOLUME ["/var/lib/postgresql/data"]
</code>

En la carpeta donde se colocan ambos archivos, se debe crear una carpeta llamada import_data. Dentro de esa carpeta se debem colocar los archivos csv descargados desde Kaggle.
Cuando estÃ© todo listo, sÃ³lo debemos abrir Docker Desktop (una vez instalado) y seleccionar la opciÃ³n mostrada en rojo. Eso nos abrirÃ¡ la terminal indicada en verde

<img src="Documentacion/imagenes/docker1.png">

En la terminal, debemos escribir <i>cd <span style="color: red">ruta</span></i>, donde <span style="color: red">ruta</span> indica la ruta de la carpeta donde colocamos el archivo composer-yaml y Dockerfile.

<img src="Documentacion/imagenes/docker2.png">

En la imagen anterior vemos los comandos de la terminal de Docker. Primero, lo indicado en verde, es para ir al directorio en donde tenemos colocados los archivos composer-yaml y Dockerfile. Lo indicado en rojo es la manera de levantar las imÃ¡genes: <i><b>docker-compose up -d postgres pgadmin</b></i>.
Si es la primera vez que ejecutan el comando, tardarÃ¡ unos minutos en traer las imÃ¡genes desde Docker Hub y, despuÃ©s de un tiempo, deben ver algo similar a esto en la terminal:

<img src="Documentacion/imagenes/docker3.png">

Si les aparece eso, entonces todo estÃ¡ funcionando correctamente. PodrÃ¡n entrar al pgadmin haciendo: <i>localhost:8080</i>

<img src="Documentacion/imagenes/docker4.png">

El usuario es <i>admin@example.com</i> y la contraseÃ±a serÃ¡ <i>admin123</i>. Los archivos para docker lo pueden encontrar en <i><b>Documentacion/archivos/docker</b></i>

<img src="Documentacion/imagenes/docker5.png">

La Ãºltima imagen muestra un ejemplo de cÃ³mo debe quedar la carpeta con los archivos. Si se clona este repositorio y se ejecutan los comandos de Docker, serÃ¡ allÃ­ donde se guarden las imÃ¡genes y volumenes del mismo. Pero, si quieres colocarlo en una carpeta en particular, sÃ³lo debes bajar los archivos composer-yaml, Dockerfile y colocarlo en la carpeta deseada. La carpeta indicada en azul es la que crea Docker. Pero la carpeta indica en rojo debes crearla manualmente y colocar allÃ­ los archivos CSV.

### Creando El Servidor y La Base De Datos

Una vez que se haya iniciado sesiÃ³n en pgadmin, lo primero es crear un servidor para empezar a trabajar. Para ello, en las opciones de la izquierda hacemos click derecho en <i>Servers->Register->Server</i>

<img src="Documentacion/imagenes/pgadmin1.png">

Eso nos mostrarÃ¡ las opciones generales

<img src="Documentacion/imagenes/pgadmin2.png">

Y las opciones de conexiÃ³n

<img src="Documentacion/imagenes/pgadmin3.png">

En las opciones de conexiÃ³n, si se usan los documentos de docker indicados en este repositorio, debemos colocar los siguientes datos para el <span style="color: red">host</span>, <span style="color: green">usuario</span> y <span style="color: blue">constraseÃ±a</span> 

<img src="Documentacion/imagenes/pgadmin4.png">

Si le damos a la opciÃ³n Save, obtendremos el resultado mostrado en la siguiente imagen y con eso nuestro servidor estarÃ¡ listo.

<img src="Documentacion/imagenes/pgadmin5.png">

En la imagen superior se pueden ver varias bases de datos creadas, pero es posible que en tu caso no veas ni una, o quizÃ¡s sÃ³lo veas la base de datos llamada postgres. En cualquier caso, debes crear una nueva base de datos haciendo click derecho sobre el nombre del servidor, luego la opciÃ³n Create y finalmente la opciÃ³n Database

<img src="Documentacion/imagenes/pgadmin6.png">

Le damos un nombre a la base de datos y la creamos

<img src="Documentacion/imagenes/pgadmin7.png">

Se da click en el botÃ³n Save y la base de datos debe estar creada

<img src="Documentacion/imagenes/pgadmin8.png">

Una forma rÃ¡pida para ejecutar los scripts en pgadmin es hacer click derecho sobre la base de datos creada y elegir la opciÃ³n Query Tool

<img src="Documentacion/imagenes/pgadmin9.png">

Esto nos abrirÃ¡ una ventana donde podremos realizar consultas SQL. Nos daremos cuenta que esa venta ejecutarÃ¡ las consultas SQL sobre la base de datos en cuestiÃ³n porque veremos seÃ±alado el nombre de la base de datos, como lo muestra la siguiente imagen

<img src="Documentacion/imagenes/pgadmin10.png">

AllÃ­ podremos pegar los cÃ³digos de nuestros scripts. Por ejemplo, podemos abrir el script <i>ddl_bronze_layer.sql</i> y copiar ese cÃ³digo en la ventana de query que acabamos de crear. Luego, simplemente le damos a F5 y se crearÃ¡n las tablas de la capa bronze. <b>Es importante que previamente los archivos CSV estÃ©n colocados en la carpeta que se indicÃ³ anteriormente.</b>
<hr style="border: solid black 0.5em">

## ğŸ“š Referencias

1.  Olist Dataset (Kaggle):https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/
2.  Baraa Khatib -- Data Warehouse Project: https://github.com/DataWithBaraa/sql-data-warehouse-project
3.  SQL Data Warehouse from Scratch | Full Hands-On Data Engineering Project-Data with Baraa: https://www.youtube.com/watch?v=9GVqKuTVANE&list=PLNcg_FV9n7qaUWeyUkPfiVtMbKlrfMqA8
4.  Lista de MunicÃ­pios Brasileiros e InformaÃ§Ãµes Adicionais: https://blog.mds.gov.br/redesuas/lista-de-municipios-brasileiros/
5.  Postgres SQL Generar diccionario de datos: https://gist.github.com/juelvaldivia/15f90280a86997faca1cf5997ff0a683
6.  DocumentaciÃ³n De Docker: https://docs.docker.com/
7. DocumentaciÃ³n PostgreSQL: https://www.postgresql.org/docs/
